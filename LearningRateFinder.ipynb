{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import json\n",
    "import PIL\n",
    "from PIL import ImageDraw, ImageFont,Image, ImageOps, ImageEnhance\n",
    "from matplotlib import patches, patheffects\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import transforms,models\n",
    "from torchvision.utils import make_grid\n",
    "import math\n",
    "import random\n",
    "import numbers\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import glob\n",
    "from skimage import io\n",
    "from torch.autograd import Variable as V\n",
    "from scipy import ndimage\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import skimage\n",
    "torch.backends.cudnn.benchmark=True\n",
    "torch.cuda.set_device(0)\n",
    "import scipy\n",
    "def sum_geom(a,r,n): return a*n if r==1 else math.ceil(a*(1-r**n)/(1-r))\n",
    "def is_listy(x): return isinstance(x, (list,tuple))\n",
    "def is_iter(x): return isinstance(x, collections.Iterable)\n",
    "def map_over(x, f): return [f(o) for o in x] if is_listy(x) else f(x)\n",
    "def map_none(x, f): return None if x is None else f(x)\n",
    "def delistify(x): return x[0] if is_listy(x) else x\n",
    "def listify(x, y):\n",
    "    if not is_iter(x): x=[x]\n",
    "    n = y if type(y)==int else len(y)\n",
    "    if len(x)==1: x = x * n\n",
    "    return x\n",
    "\n",
    "def datafy(x):\n",
    "    if is_listy(x): return [o.data for o in x]\n",
    "    else:           return x.data\n",
    "\n",
    "conv_dict = {np.dtype('int8'): torch.LongTensor, np.dtype('int16'): torch.LongTensor,\n",
    "    np.dtype('int32'): torch.LongTensor, np.dtype('int64'): torch.LongTensor,\n",
    "    np.dtype('float32'): torch.FloatTensor, np.dtype('float64'): torch.FloatTensor}\n",
    "\n",
    "def A(*a):\n",
    "    \"\"\"convert iterable object into numpy array\"\"\"\n",
    "    return np.array(a[0]) if len(a)==1 else [np.array(o) for o in a]\n",
    "\n",
    "def T(a, half=False, cuda=True):\n",
    "    \"\"\"\n",
    "    Convert numpy array into a pytorch tensor. \n",
    "    if Cuda is available and USE_GPU=True, store resulting tensor in GPU.\n",
    "    \"\"\"\n",
    "    if not torch.is_tensor(a):\n",
    "        a = np.array(np.ascontiguousarray(a))\n",
    "        if a.dtype in (np.int8, np.int16, np.int32, np.int64):\n",
    "            a = torch.LongTensor(a.astype(np.int64))\n",
    "        elif a.dtype in (np.float32, np.float64):\n",
    "            a = to_half(a) if half else torch.FloatTensor(a)\n",
    "        else: raise NotImplementedError(a.dtype)\n",
    "    if cuda: a = to_gpu(a)\n",
    "    return a\n",
    "\n",
    "def to_half(tensor):\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.cuda.HalfTensor(tensor)\n",
    "    else:\n",
    "        return torch.FloatTensor(tensor)\n",
    "\n",
    "def create_variable(x, volatile, requires_grad=False):\n",
    "    if type (x) != Variable:\n",
    "        x = Variable(T(x), requires_grad=requires_grad, volatile=volatile)\n",
    "    return x\n",
    "\n",
    "def V_(x, requires_grad=False, volatile=False):\n",
    "    '''equivalent to create_variable, which creates a pytorch tensor'''\n",
    "    return create_variable(x, volatile=volatile, requires_grad=requires_grad)\n",
    "def V(x, requires_grad=False, volatile=False):\n",
    "    '''creates a single or a list of pytorch tensors, depending on input x. '''\n",
    "    return map_over(x, lambda o: V_(o, requires_grad, volatile))\n",
    "\n",
    "def VV_(x): \n",
    "    '''creates a volatile tensor, which does not require gradients. '''\n",
    "    return create_variable(x, True)\n",
    "\n",
    "def VV(x):\n",
    "    '''creates a single or a list of pytorch tensors, depending on input x. '''\n",
    "    return map_over(x, VV_)\n",
    "\n",
    "def to_np(v):\n",
    "    '''returns an np.array object given an input of np.array, list, tuple, torch variable or tensor.'''\n",
    "    if isinstance(v, float): return np.array(v)\n",
    "    if isinstance(v, (np.ndarray, np.generic)): return v\n",
    "    if isinstance(v, (list,tuple)): return [to_np(o) for o in v]\n",
    "    if isinstance(v, Variable): v=v.data\n",
    "    if torch.cuda.is_available():\n",
    "        if is_half_tensor(v): v=v.float()\n",
    "    if isinstance(v, torch.FloatTensor): v=v.float()\n",
    "    return v.cpu().numpy()\n",
    "\n",
    "def is_half_tensor(v):\n",
    "    return isinstance(v, torch.cuda.HalfTensor)\n",
    "\n",
    "\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "def to_gpu(x, *args, **kwargs):\n",
    "    '''puts pytorch variable to gpu, if cuda is available and USE_GPU is set to true. '''\n",
    "    return x.cuda(*args, **kwargs) if USE_GPU else x\n",
    "\n",
    "def noop(*args, **kwargs): return\n",
    "\n",
    "def trainable_params_(m):\n",
    "    '''Returns a list of trainable parameters in the model m. (i.e., those that require gradients.)'''\n",
    "    return [p for p in m.parameters() if p.requires_grad]\n",
    "\n",
    "def chain_params(p):\n",
    "    if is_listy(p):\n",
    "        return list(chain(*[trainable_params_(o) for o in p]))\n",
    "    return trainable_params_(p)\n",
    "\n",
    "def set_trainable_attr(m,b):\n",
    "    m.trainable=b\n",
    "    for p in m.parameters(): p.requires_grad=b\n",
    "\n",
    "def apply_leaf(m, f):\n",
    "    c = children(m)\n",
    "    if isinstance(m, nn.Module): f(m)\n",
    "    if len(c)>0:\n",
    "        for l in c: apply_leaf(l,f)\n",
    "def children(m): return m if isinstance(m, (list, tuple)) else list(m.children())\n",
    "def set_trainable(l, b):\n",
    "    apply_leaf(l, lambda m: set_trainable_attr(m,b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('dataSet/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab the training and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_set = datasets.MNIST(PATH, train=True, download=True)\n",
    "tst_set = datasets.MNIST(PATH, train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the data in the training set first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_set.train_data), len(tst_set.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image is represented by a tensor of size 28 by 28, each value represents the color of the corresponding pixel, from 0 (black) to 255 (white). Torch tensors are the equivalent of numpy ndarrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easy to convert a torch tensor to a numpy array via the .numpy() command.\n",
    "\n",
    "Conversely, you can create a torch Tensor from a numpy array x via torch.Tensor(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's then easy to see the corresponding picture via plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ee9f6ab668>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(trn_set.train_data[0].numpy(), cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the corresponding label..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_set.train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfms = transforms.ToTensor()\n",
    "trn_set = datasets.MNIST(PATH, train=True, download=True, transform=tsfms)\n",
    "tst_set = datasets.MNIST(PATH, train=False, download=True, transform=tsfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_loader = torch.utils.data.DataLoader(trn_set, batch_size=64, shuffle=True, num_workers=0)\n",
    "tst_loader = torch.utils.data.DataLoader(tst_set, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at an example. A data loader can be converted into an iterator and we can then ask him for a minibatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_example = next(iter(trn_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb_example[0].size(), mb_example[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1306), tensor(0.3081))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = torch.mean(trn_set.train_data.type(torch.FloatTensor))/255.\n",
    "std = torch.std(trn_set.train_data.type(torch.FloatTensor))/255.\n",
    "mean,std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide by 255 to get the means of our data when it's convereted into floats from 0. to 1.\n",
    "\n",
    "Then we go back to creating a transfrom and add the normalization. Note that we use the same mean and std for the test set. Afterward, we reload our datasets, adding this transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((mean,), (std,))])\n",
    "trn_set = datasets.MNIST(PATH, train=True, download=True, transform=tsfms)\n",
    "tst_set = datasets.MNIST(PATH, train=False, download=True, transform=tsfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_loader = torch.utils.data.DataLoader(trn_set, batch_size=64, shuffle=True, num_workers=0)\n",
    "tst_loader = torch.utils.data.DataLoader(tst_set, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self, n_in, n_hidden, n_out):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(n_in, n_hidden)\n",
    "        self.linear2 = nn.Linear(n_hidden, n_out)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        return F.log_softmax(self.linear2(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimpleNeuralNet(28*28,100,10).cuda()\n",
    "optimizer = optim.SGD(net.parameters(),lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(nb_epoch):\n",
    "    for epoch in range(nb_epoch):\n",
    "        running_loss = 0.\n",
    "        corrects = 0\n",
    "        print(f'Epoch {epoch+1}:')\n",
    "        for data in trn_loader:\n",
    "            inputs,labels = data\n",
    "            inputs, labels = V(inputs), V(labels)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            _,preds = torch.max(outputs.data,1)\n",
    "            loss = F.nll_loss(outputs, labels)\n",
    "            running_loss += loss.data.item() * inputs.size(0)\n",
    "            corrects += torch.sum(labels.data == preds.cuda())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Loss: {running_loss/len(trn_set)}  Accuracy: {100.*corrects/len(trn_set)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Loss: 0.5788133769432704  Accuracy: 85\n",
      "Epoch 2:\n",
      "Loss: 0.3013044168869654  Accuracy: 91\n",
      "Epoch 3:\n",
      "Loss: 0.2546365159193675  Accuracy: 92\n",
      "Epoch 4:\n",
      "Loss: 0.22325895236333212  Accuracy: 93\n",
      "Epoch 5:\n",
      "Loss: 0.19944103789726894  Accuracy: 94\n"
     ]
    }
   ],
   "source": [
    "train(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "94% accuracy is good, but that's on the training set and we may be overfitting. Let's try on the test set now to see if we're doing well or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    running_loss = 0.\n",
    "    corrects = 0\n",
    "    for data in tst_loader:\n",
    "        inputs,labels = data\n",
    "        inputs, labels = V(inputs), V(labels)\n",
    "        outputs = net(inputs)\n",
    "        _,preds = torch.max(outputs.data,1)\n",
    "        loss = F.nll_loss(outputs, labels)\n",
    "        running_loss += loss.data.item() * inputs.size(0)\n",
    "        corrects += torch.sum(labels.data == preds.cuda())\n",
    "    print(f'Loss: {running_loss/len(tst_set)}  Accuracy: {100.*corrects/len(tst_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.18535682628154754  Accuracy: 94\n"
     ]
    }
   ],
   "source": [
    "validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we weren't overfitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lr(init_value = 1e-8, final_value=10., beta = 0.98):\n",
    "    num = len(trn_loader)-1\n",
    "    mult = (final_value / init_value) ** (1/num)\n",
    "    lr = init_value\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "    avg_loss = 0.\n",
    "    best_loss = 0.\n",
    "    batch_num = 0\n",
    "    losses = []\n",
    "    log_lrs = []\n",
    "    for data in trn_loader:\n",
    "        batch_num += 1\n",
    "        inputs,labels = data\n",
    "        inputs, labels = V(inputs), V(labels)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        avg_loss = beta * avg_loss + (1-beta) *loss.data.item()\n",
    "        smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
    "        if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
    "            return log_lrs, losses\n",
    "        if smoothed_loss < best_loss or batch_num==1:\n",
    "            best_loss = smoothed_loss\n",
    "        losses.append(smoothed_loss)\n",
    "        log_lrs.append(math.log10(lr))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr *= mult\n",
    "        optimizer.param_groups[0]['lr'] = lr\n",
    "    return log_lrs, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define our neural net as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimpleNeuralNet(28*28,100,10).cuda()\n",
    "optimizer = optim.SGD(net.parameters(),lr=1e-1)\n",
    "criterion = F.nll_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then plot the losses versus the logs of the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs,losses = find_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee9fa724a8>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(logs[10:-5],losses[10:-5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests the best learning rate is $10^{-1}$ so we can use test this one after defining a new network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Loss: 0.2584514814933141  Accuracy: 92\n"
     ]
    }
   ],
   "source": [
    "net = SimpleNeuralNet(28*28,100,10).cuda()\n",
    "optimizer = optim.SGD(net.parameters(),lr=1e-1)\n",
    "train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Loss: 0.11329360496997833  Accuracy: 96\n",
      "Epoch 2:\n",
      "Loss: 0.08071397163073221  Accuracy: 97\n",
      "Epoch 3:\n",
      "Loss: 0.06354744155009588  Accuracy: 98\n",
      "Epoch 4:\n",
      "Loss: 0.051555388816197714  Accuracy: 98\n"
     ]
    }
   ],
   "source": [
    "train(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are already at 92% accuracy when the learning rate used before gave us 85% in one epoch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveConcatPool2d(nn.Module):\n",
    "    def __init__(self, sz=None):\n",
    "        super().__init__()\n",
    "        sz = sz or (1,1)\n",
    "        self.ap = nn.AdaptiveAvgPool2d(sz)\n",
    "        self.mp = nn.AdaptiveMaxPool2d(sz)\n",
    "    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)\n",
    "    \n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self, keep_batch_dim=True):\n",
    "        super().__init__()\n",
    "        self.keep_batch_dim = keep_batch_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.keep_batch_dim:\n",
    "            return x.view(x.size(0), -1)\n",
    "        return x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BnLayer(nn.Module):\n",
    "    def __init__(self, ni, nf, stride=2, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(ni, nf, kernel_size=kernel_size, stride=stride,\n",
    "                              bias=False, padding=1)\n",
    "        self.a = nn.Parameter(torch.zeros(nf,1,1))\n",
    "        self.m = nn.Parameter(torch.ones(nf,1,1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv(x))\n",
    "        x_chan = x.transpose(0,1).contiguous().view(x.size(1), -1)\n",
    "        if self.training:\n",
    "            self.means = x_chan.mean(1)[:,None,None]\n",
    "            self.stds  = x_chan.std (1)[:,None,None]\n",
    "        return (x-self.means) / self.stds *self.m + self.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBnNet(nn.Module):\n",
    "    def __init__(self, layers, c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5, stride=1, padding=2)\n",
    "        self.layers = nn.ModuleList([BnLayer(layers[i], layers[i + 1])\n",
    "            for i in range(len(layers) - 1)])\n",
    "        self.out = nn.Linear(layers[-1], c)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        for l in self.layers: x = l(x)\n",
    "        x = F.adaptive_max_pool2d(x, 1)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return F.log_softmax(self.out(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ConvBnNet([10, 20, 40,80,160], 10)\n",
    "net = nn.DataParallel(net, device_ids=None)\n",
    "optimizer = optim.SGD(net.parameters(),lr=1e-1)\n",
    "criterion = F.nll_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Loss: 0.11037411624590555  Accuracy: 96\n"
     ]
    }
   ],
   "source": [
    "train(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initially we got an accuracy of 85% using simple neural net then we use learning rate finder and we got an accuracy of 92% in one epoch and using CNN and batch norm we got an accuracy of 96% in one epoch  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Loss: 0.03743914530674616  Accuracy: 98\n",
      "Epoch 2:\n",
      "Loss: 0.02325316725174586  Accuracy: 99\n",
      "Epoch 3:\n",
      "Loss: 0.015216404219468434  Accuracy: 99\n",
      "Epoch 4:\n",
      "Loss: 0.009684098033110301  Accuracy: 99\n"
     ]
    }
   ],
   "source": [
    "train(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.03032072174549103  Accuracy: 98\n"
     ]
    }
   ],
   "source": [
    "validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are having good accuracy on training set and validation set ie 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
